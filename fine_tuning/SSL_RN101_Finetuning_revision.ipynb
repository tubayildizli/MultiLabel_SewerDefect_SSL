{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semi-Supervised Learning with ResNet101 for Sewer Defect Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Library Imports and Setup\n",
    "- Import essential PyTorch libraries and utilities\n",
    "- Set up Weights & Biases (wandb) for experiment tracking\n",
    "- Configure API keys and project settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import pandas as pd\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from PIL import Image\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import wandb\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "# Set the wandb API key\n",
    "os.environ['WANDB_API_KEY'] = 'YOUR_WANDB_API_KEY'  # Replace with your key\n",
    "\n",
    "# Initialize wandb\n",
    "wandb.login()\n",
    "wandb.init(project=\"your_project_name\")  # Replace with your project name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Dataset Preparation\n",
    "- Define CustomDataset class for handling multi-label image data\n",
    "- Implement data transformations for training and inference:\n",
    "  - Resize images to 224x224\n",
    "  - Apply data augmentation (horizontal flip, color jitter)\n",
    "  - Normalize with domain-specific mean/std values (from Sewer-ML paper)\n",
    "- Create separate transforms for training and inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom dataset class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, csv_file, img_dir, transform=None):\n",
    "        self.annotations = pd.read_csv(csv_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = f\"{self.img_dir}/{self.annotations.iloc[idx, 0]}\"\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        labels = torch.tensor(self.annotations.iloc[idx, 1:].astype('float32').values)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, labels\n",
    "    \n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.523, 0.453, 0.345], std=[0.210, 0.199, 0.154])\n",
    "])\n",
    "\n",
    "\n",
    "inference_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.523, 0.453, 0.345], std=[0.210, 0.199, 0.154])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data Loading\n",
    "- Initialize train and validation datasets\n",
    "- Configure DataLoader with:\n",
    "  - Batch size of 128\n",
    "  - 8 worker processes\n",
    "  - Pin memory for faster GPU transfer\n",
    "- Enable shuffling for training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset instances\n",
    "train_dataset = CustomDataset(csv_file='${TRAIN_BATCH_CSV_ROOT}',\n",
    "                              img_dir='${TRAIN_IMAGE_ROOT}', transform=transform)\n",
    "val_dataset = CustomDataset(csv_file='${VAL_BATCH_CSV_ROOT}', \n",
    "                            img_dir='${VAL_IMAGE_ROOT}', transform=inference_transform)\n",
    "\n",
    "# Create dataloaderss\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=8, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False, num_workers=8, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. SSL Model Loading\n",
    "Loads the self-supervised pre-trained model:\n",
    "- Loads checkpoint from SwAV pre-training\n",
    "- Extracts state dictionary and handles key mapping\n",
    "- Initializes ResNet101 architecture\n",
    "- Removes prefix from state dict keys\n",
    "- Key difference: Loads SSL pre-trained weights instead of ImageNet weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the entire checkpoint\n",
    "checkpoint = torch.load('../checkpoints/SSL_model_weights/${SSL_MODEL_WEIGHTS}', map_location=torch.device('cpu'))\n",
    "\n",
    "# Check the keys in the checkpoint\n",
    "print(\"Keys in the checkpoint:\", list(checkpoint.keys()))\n",
    "\n",
    "# Extract the state_dict from 'classy_state_dict'\n",
    "classy_state_dict = checkpoint['classy_state_dict']\n",
    "\n",
    "# Check the keys inside classy_state_dict\n",
    "print(\"Keys in 'classy_state_dict':\", list(classy_state_dict.keys()))\n",
    "\n",
    "# Extract the state_dict from 'base_model'\n",
    "base_model_state_dict = classy_state_dict['base_model']['model']['trunk']\n",
    "\n",
    "# Print some keys to understand the structure\n",
    "print(\"Keys in the extracted base_model_state_dict:\")\n",
    "print(list(base_model_state_dict.keys())[:10])\n",
    "\n",
    "model = models.resnet101(weights=None)\n",
    "\n",
    "# Function to remove prefix\n",
    "def remove_prefix(state_dict, prefix):\n",
    "    new_state_dict = {}\n",
    "    for k, v in state_dict.items():\n",
    "        if k.startswith(prefix):\n",
    "            new_key = k[len(prefix):]  # Remove the prefix\n",
    "            new_state_dict[new_key] = v\n",
    "        else:\n",
    "            new_state_dict[k] = v\n",
    "    return new_state_dict\n",
    "\n",
    "# Remove '_feature_blocks.' prefix from keys\n",
    "filtered_state_dict = remove_prefix(base_model_state_dict, '_feature_blocks.')\n",
    "\n",
    "# Print filtered keys to verify\n",
    "print(\"Keys in the filtered state_dict:\")\n",
    "print(list(filtered_state_dict.keys())[:10])\n",
    "\n",
    "# Filter out keys that do not match\n",
    "filtered_state_dict = {k: v for k, v in filtered_state_dict.items() if k in model.state_dict()}\n",
    "\n",
    "# Load the filtered state dictionary into the model\n",
    "missing_keys, unexpected_keys = model.load_state_dict(filtered_state_dict, strict=False)\n",
    "\n",
    "# Print missing and unexpected keys\n",
    "print(\"Missing keys after loading state_dict:\")\n",
    "print(missing_keys)\n",
    "\n",
    "print(\"Unexpected keys after loading state_dict:\")\n",
    "print(unexpected_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Model Architecture Modification\n",
    "Adapts the pre-trained model for the defect classification task:\n",
    "- Replaces final FC layer with 17-class output\n",
    "- Moves model to available device (GPU/CPU)\n",
    "- Verifies parameter statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefine the fully connected layer to match the number of classes in your task (e.g., 18 classes)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = torch.nn.Sequential(\n",
    "    torch.nn.Linear(num_ftrs, 17)\n",
    "    # torch.nn.Sigmoid()\n",
    ")\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# Verify parameter statistics\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: mean={param.mean().item()}, std={param.std().item()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Loss Function and Class Weighting\n",
    "Implements weighted loss for handling class imbalance:\n",
    "- Calculates positive/negative sample ratios\n",
    "- Applies square root moderation to weights\n",
    "- Implements BCEWithLogitsLoss with pos_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balanced pos_weight with moderation for better precision-recall balance\n",
    "all_labels = []\n",
    "for _, labels in train_loader:\n",
    "    all_labels.append(labels)\n",
    "all_labels = torch.cat(all_labels, dim=0) \n",
    "\n",
    "num_pos = all_labels.sum(dim=0)\n",
    "num_neg = (all_labels == 0).sum(dim=0)\n",
    "raw_pos_weight = num_neg / (num_pos + 1e-8)\n",
    "\n",
    "# Moderate the pos_weight to balance precision and recall\n",
    "# Clip extreme weights and apply square root to reduce impact\n",
    "pos_weight = torch.sqrt(torch.clamp(raw_pos_weight, min=1.0, max=10.0))\n",
    "pos_weight = pos_weight.to(device)\n",
    "\n",
    "print(\"Class distribution (positive samples):\", num_pos.numpy())\n",
    "print(\"Applied pos_weight:\", pos_weight.cpu().numpy())\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Training Configuration\n",
    "- Define SGD optimizer with:\n",
    "  - Learning rate: 0.01\n",
    "  - Momentum: 0.9\n",
    "  - Weight decay: 0.0001\n",
    "- Set up MultiStepLR scheduler\n",
    "- Implement metric calculation for precision, recall, and F1\n",
    "- Define training loop with validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Higher initial LR since less data needs more aggressive learning\n",
    "# - SGD with momentum (as per original paper) for better generalization on small data\n",
    "# - More conservative LR decay schedule adapted for fewer epochs\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0001)\n",
    "scheduler = lr_scheduler.MultiStepLR(optimizer, milestones=[10, 20, 25], gamma=0.1)\n",
    "\n",
    "\n",
    "def calculate_metrics(labels, outputs, threshold=0.5):\n",
    "    # Apply sigmoid and thresholding\n",
    "    outputs = torch.sigmoid(outputs)\n",
    "    outputs = (outputs > threshold).float()\n",
    "\n",
    "    # Derive \"ND\" (no defect) as 18th class\n",
    "    labels_nd = (labels.sum(dim=1) == 0).float().unsqueeze(1)\n",
    "    outputs_nd = (outputs.sum(dim=1) == 0).float().unsqueeze(1)\n",
    "\n",
    "    # Extend label and prediction tensors\n",
    "    labels_ext = torch.cat([labels, labels_nd], dim=1)\n",
    "    outputs_ext = torch.cat([outputs, outputs_nd], dim=1)\n",
    "\n",
    "    # Convert to numpy\n",
    "    y_true = labels_ext.numpy()\n",
    "    y_pred = outputs_ext.numpy()\n",
    "\n",
    "    # Compute metrics\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro', zero_division=0)\n",
    "    return precision, recall, f1\n",
    "\n",
    "\n",
    "# Training function\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=30, save_interval=15, checkpoint_dir=\"${YOUR_PROJECT_ROOT}/checkpoints/fine_tuning/SSL/${FINE_TUNING_BATCH}\"):\n",
    "    if not os.path.exists(checkpoint_dir):\n",
    "        os.makedirs(checkpoint_dir)\n",
    "   \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        \n",
    "        # Log training loss to wandb\n",
    "        wandb.log({\"Train Loss\": epoch_loss, \"epoch\": epoch})\n",
    "\n",
    "        # Validate the model\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        all_labels = []\n",
    "        all_outputs = []\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                all_labels.append(labels.cpu())\n",
    "                all_outputs.append(outputs.cpu())\n",
    "        \n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        all_labels = torch.cat(all_labels)\n",
    "        all_outputs = torch.cat(all_outputs)\n",
    "        precision, recall, f1 = calculate_metrics(all_labels, all_outputs)\n",
    "        \n",
    "        # Log validation metrics to wandb\n",
    "        wandb.log({\n",
    "            \"Val Loss\": val_loss,\n",
    "            \"Val Precision\": precision,\n",
    "            \"Val Recall\": recall,\n",
    "            \"Val F1 Score\": f1,\n",
    "            \"epoch\": epoch\n",
    "        })\n",
    "        \n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}, Train Loss: {epoch_loss:.4f}, Val Loss: {val_loss:.4f}, Val Precision: {precision:.4f}, Val Recall: {recall:.4f}, Val F1 Score: {f1:.4f}')\n",
    "        \n",
    "        # Save the model checkpoint every save_interval epochs\n",
    "        if (epoch + 1) % save_interval == 0:\n",
    "            checkpoint_path = os.path.join(checkpoint_dir, f\"model_epoch_{epoch + 1}.pth\")\n",
    "            torch.save(model.state_dict(), checkpoint_path)\n",
    "            print(f\"Model checkpoint saved at epoch {epoch + 1}\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Model Training\n",
    "- Execute training loop for 30 epochs\n",
    "- Track metrics using wandb\n",
    "- Save model checkpoints periodically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train_model(model, criterion, optimizer, scheduler, num_epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Evaluation Function\n",
    "- Define comprehensive evaluation function\n",
    "- Calculate per-class and overall metrics\n",
    "- Handle \"No Defect\" (ND) class specially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "def evaluate_model(model, dataloader, threshold=0.5, save_images=False):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_outputs = []\n",
    "    images = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            all_labels.append(labels.cpu())\n",
    "            all_outputs.append(outputs.cpu())\n",
    "            if save_images:\n",
    "                images.append(inputs.cpu())\n",
    "\n",
    "    # Concatenate all batches\n",
    "    all_labels = torch.cat(all_labels)\n",
    "    all_outputs = torch.cat(all_outputs)\n",
    "\n",
    "    # Apply sigmoid and thresholding\n",
    "    all_outputs = torch.sigmoid(all_outputs)\n",
    "    all_outputs = (all_outputs > threshold).float()\n",
    "\n",
    "    # Derive \"ND\" (no defect) as 18th class\n",
    "    labels_nd = (all_labels.sum(dim=1) == 0).float().unsqueeze(1)\n",
    "    outputs_nd = (all_outputs.sum(dim=1) == 0).float().unsqueeze(1)\n",
    "\n",
    "    # Extend label and output tensors\n",
    "    labels_ext = torch.cat([all_labels, labels_nd], dim=1)\n",
    "    outputs_ext = torch.cat([all_outputs, outputs_nd], dim=1)\n",
    "\n",
    "    # Convert to numpy\n",
    "    y_true = labels_ext.numpy()\n",
    "    y_pred = outputs_ext.numpy()\n",
    "\n",
    "    # Compute per-class metrics\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average=None, zero_division=0)\n",
    "    overall_precision, overall_recall, overall_f1, _ = precision_recall_fscore_support(y_true, y_pred, average='micro', zero_division=0)\n",
    "\n",
    "    for i in range(len(precision)):\n",
    "        class_label = f'Class {i}' if i < labels_ext.shape[1] - 1 else 'Class 17 (ND)'\n",
    "        print(f'{class_label} - Precision: {precision[i]:.4f}, Recall: {recall[i]:.4f}, F1 Score: {f1[i]:.4f}')\n",
    "\n",
    "    print(f'\\nOverall - Precision: {overall_precision:.4f}, Recall: {overall_recall:.4f}, F1 Score: {overall_f1:.4f}')\n",
    "    return y_true, y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Test Dataset Evaluation\n",
    "- Load and prepare test dataset\n",
    "- Run model evaluation on test set\n",
    "- Calculate final performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CustomDataset(csv_file='{YOUR_PROJECT_ROOT}/data/fine_tuning/annotations/test/test_labels.csv', \n",
    "                            img_dir='{YOUR_PROJECT_ROOT}/data/fine_tuning/images/test', transform=inference_transform)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=8, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred = evaluate_model(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Metrics Computation\n",
    "- Apply CIW (Class Importance Weights) from Sewer-ML paper\n",
    "- Calculate specialized metrics:\n",
    "  - Class-weighted F2 score\n",
    "  - Normal class F1 score\n",
    "  - Mean Average Precision\n",
    "  - Exact Match Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics import evaluation\n",
    "import numpy as np\n",
    "\n",
    "# Actual CIW weights from the Sewer-ML paper\n",
    "ciw_weights = np.array([\n",
    "    1.0000,  # RB\n",
    "    0.5518,  # OB\n",
    "    0.2896,  # PF\n",
    "    0.1622,  # DE\n",
    "    0.6419,  # FS\n",
    "    0.1847,  # IS\n",
    "    0.3559,  # RO\n",
    "    0.3131,  # IN\n",
    "    0.0811,  # AF\n",
    "    0.2275,  # BE\n",
    "    0.2477,  # FO\n",
    "    0.0901,  # GR\n",
    "    0.4167,  # PH\n",
    "    0.4167,  # PB\n",
    "    0.9009,  # OS\n",
    "    0.3829,  # OP\n",
    "    0.4396   # OK\n",
    "])\n",
    "\n",
    "# Example: y_pred = model outputs after sigmoid and thresholding\n",
    "# y_true = ground truth labels\n",
    "\n",
    "# If you have torch tensors, convert to numpy:\n",
    "# y_true = y_true_tensor.numpy()\n",
    "# y_pred = y_pred_tensor.numpy()\n",
    "y_true_defects = y_true[:, :17]\n",
    "y_pred_defects = y_pred[:, :17]\n",
    "\n",
    "\n",
    "new_metrics, main_metrics, aux_metrics = evaluation(y_pred_defects, y_true_defects, ciw_weights, threshold=0.5)\n",
    "f1_normal = new_metrics[\"F1_Normal\"]\n",
    "print(\"F1-score for ND (Normal):\", f1_normal)\n",
    "print(\"Main metrics:\", main_metrics)\n",
    "print(\"Class-weighted F2 (CIW-F2):\", new_metrics[\"F2\"])\n",
    "print(\"Per-class F2:\", new_metrics[\"F2_class\"])\n",
    "print(\"Macro F1:\", main_metrics[\"MF1\"])\n",
    "print(\"Micro F1:\", main_metrics[\"mF1\"])\n",
    "print(\"Mean Average Precision (mAP):\", main_metrics[\"mAP\"])\n",
    "print(\"Exact Match Accuracy:\", main_metrics[\"EMAcc\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
